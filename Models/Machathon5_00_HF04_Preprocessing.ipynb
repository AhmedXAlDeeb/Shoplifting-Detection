{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import collections\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import keras\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from io import BytesIO\n",
        "from tensorflow.keras.models import load_model\n",
        "\n"
      ],
      "metadata": {
        "id": "1WpuAOTkO_v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_1 link:\n",
        "'''\n",
        "https://drive.google.com/file/d/1mH7HknToTEIu4mcHpZHTU-1XBnAYmEPa/view?usp=sharing\n",
        "'''\n",
        "#model_2 link:\n",
        "'''\n",
        "https://drive.google.com/file/d/1-NAJfiybE2_ElioP8tvU-DyE1r3K21mn/view?usp=sharing\n",
        "'''"
      ],
      "metadata": {
        "id": "i8Kl4Td8ROXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fe3bEBsXO_g4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_folder(link):\n",
        "  '''\n",
        "  download your test data innto the enviroment\n",
        "  '''\n",
        "  path= ''\n",
        "\n",
        "  return path"
      ],
      "metadata": {
        "id": "69M-sywaN0cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVo-dI_qUgyA"
      },
      "outputs": [],
      "source": [
        "def submit(folder_link):\n",
        "  model_prediction=[]\n",
        "  '''\n",
        "  Return:\n",
        "  model_prediction -> list of zeros and ones based on the prediction for each video in the folder (0 -> not shop lifter | 1-> shop lifter)\n",
        "\n",
        "  Args:\n",
        "  folder_link -> link for a folder has some videos to predict\n",
        "\n",
        "  '''\n",
        "\n",
        "  # write your code here\n",
        "  # load your model weights\n",
        "  # loop on all the videos in the folder_link\n",
        "  # append the predictions to the list model_prediction\n",
        "\n",
        "  model_1 , model_2 = load_my_model()\n",
        "\n",
        "\n",
        "  folder_path = download_folder(folder_link)\n",
        "\n",
        "  files = [f for f in os.listdir(folder_path) if f.endswith(('.mp4', '.avi', '.mkv'))]\n",
        "  for video_file in folder_path:\n",
        "      video_path = os.path.join(folder_path, video_file)\n",
        "      model_prediction.append(predict_one(model_1, model_2, video_path))\n",
        "\n",
        "\n",
        "\n",
        "  # Note : the returned predictions should be 0 or 1 (0 -> not shop lifter | 1-> shop lifter)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "  return model_prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def single_video_preprocessing(video_path, SEQUENCE_LENGTH ):\n",
        "  '''\n",
        "  this function preprocess only one video\n",
        "  video path >> is a path to the video dowwnloaded into the working enviroment\n",
        "\n",
        "  sequence lenght >> is the number of frames it is origanally 20\n",
        "\n",
        "  return type is alist of shape (20, 64, 64, 3)\n",
        ")\n",
        "  '''\n",
        "\n",
        "    # Initialize the VideoCapture object to read from the video file.\n",
        "  video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "   # Get the width and height of the video\n",
        "  original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    # Declare a list to store video frames we will extract.\n",
        "  frames_list = []\n",
        "\n",
        "   # Initialize a variable to store the predicted action being performed in the video.\n",
        "  predicted_class_name = ''\n",
        "\n",
        "   # Get the number of frames in the video.\n",
        "  video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  video_fps = video_reader.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "  skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
        "\n",
        "  for frame_counter in range(SEQUENCE_LENGTH):\n",
        "      # Set the current frame position of the video.\n",
        "    video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "      # Read a frame.\n",
        "    success, frame = video_reader.read()\n",
        "      # Check if frame is not read properly then break the loop.\n",
        "    if not success:\n",
        "      break\n",
        "\n",
        "     # Resize the Frame to fixed Dimensions.\n",
        "    resized_frame = cv2.resize(frame, (64, 64))\n",
        "\n",
        "     # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1.\n",
        "    normalized_frame = resized_frame / 255\n",
        "\n",
        "     # Appending the pre-processed frame into the frames list\n",
        "    frames_list.append(normalized_frame)\n",
        "\n",
        "  video_reader.release()\n",
        "\n",
        "  return frames_list"
      ],
      "metadata": {
        "id": "oVnzC3ImIKVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_my_model():\n",
        "  ##! gdown --id 1LDyrBdoS5CIsBNPMNzvoTZKpYqe-wgXL\n",
        "  #model_1 link (must be 1)\n",
        "  model_1 = tf.keras.saving.load_model(\"/content/convlstm_model_1__Date_Time_2024_03_0812_15_10_Loss_1.6097403764724731__Accuracy_0.6610169410705566.h5\")\n",
        "  #model_2 link (must be 2)\n",
        "  model_2 = tf.keras.saving.load_model(\"/content/convlstm_model_2__Date_Time_2024_03_0811_58_22_Loss_0.2769467234611511__Accuracy_0.8717948794364929.h5\")\n",
        "  return model_1,model_2"
      ],
      "metadata": {
        "id": "LWbFgKE3KxQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one(model_1, model_2, file_path):\n",
        "  input = []\n",
        "  input.append(single_video_preprocessing(file_path, 20))\n",
        "  input = np.array(input)\n",
        "  mymodel_1 = model_1\n",
        "  mymodel_2 = model_2\n",
        "\n",
        "  prob1 = mymodel_1.predict(input)\n",
        "  prob2 = mymodel_2.predict(input)\n",
        "  prob1 = prob1.tolist()\n",
        "  prob2 = prob2.tolist()\n",
        "\n",
        "  sl_1 = prob1[0][0]\n",
        "  normal = prob1[0][1]\n",
        "  tb_1 = prob1[0][2]\n",
        "\n",
        "  sl_2 = prob2[0][0]\n",
        "  sh = prob2[0][1]\n",
        "  tb_2 = prob2[0][2]\n",
        "\n",
        "  threshold = 0.3\n",
        "\n",
        "  if normal_1 < threshold: #normal is less than threshold (go to the second model)\n",
        "\n",
        "    if sl_1 > threshold: #see & let in the first model\n",
        "      if sl_2 > threshold:   #see & let in the 2nd model too (normal)\n",
        "        return 0  #print(\"normal sl\")\n",
        "      else:   # 2nd model has take & buy or shoplifter\n",
        "        return 1 #print(\"shoplift sl1\")\n",
        "\n",
        "    if tb_1 > threshold:  #take & buy happened in the first model\n",
        "      if tb_2 > threshold: # take & buy also (normal)\n",
        "        return 0   #print(\"normal tb\")\n",
        "      else:     # 2nd model is something different than we know\n",
        "        return 1  #print(\"shoplift tb1\")\n",
        "\n",
        "  else: #normal is above threshold in the first model\n",
        "    return 0  #print(\"normal\")\n"
      ],
      "metadata": {
        "id": "vb4bx24bLygf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5OofJpf1_Ue",
        "outputId": "4add7e41-e8aa-437f-e5a1-ad4504a5f4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 15, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mInzXy9JO-gN",
        "outputId": "1ca428ff-8270-4c45-a9d0-799ea8fdb6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRMG43QT1swO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}